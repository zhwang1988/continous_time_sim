package FPtree;

import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

public class FPTree {
	private static final float SUPPORT = 0.6f;
	private static long absSupport;
	
	public static Map<String,FPNode> getHeader(List<String[]> Matrix, Map<String, Integer>frequentMap){
		
		Map<String, Integer> countMap=new HashMap<String, Integer>();
		
		for (String[] line:Matrix){
			for(String idName:line){
				if (countMap.containsKey(idName)){
					//利用container,重复值覆盖的特性
					countMap.put(idName,countMap.get(idName)+1);
				}
				else{
					countMap.put(idName, 1);
				}
			}
		}
		
		//选择过滤到支持度的东西,应该仍然是一级频繁相机
		for (Entry<String, Integer> entry: countMap.entrySet()){
			if (entry.getValue()>=absSupport){
				frequentMap.put(entry.getKey(), entry.getValue());	
			}
		}
		
		//现在需要进行下排序
		List<Entry<String,Integer>> maplist=new ArrayList<Entry<String,Integer>>(frequentMap.entrySet());
		
		Collections.sort(maplist, new Comparator<Entry<String,Integer>>(){

			@Override
			public int compare(Entry<String, Integer> arg0,
					Entry<String, Integer> arg1) {
				// TODO Auto-generated method stub
					return arg0.getValue()-arg1.getValue();
			}
			
		});
		frequentMap.clear();
		//对这个Map有顺序的要求
		Map<String,FPNode> header=new LinkedHashMap<String,FPNode>();
		
		for(Entry<String, Integer> entry: maplist){
			header.put(entry.getKey(), null);
			frequentMap.put(entry.getKey(), entry.getValue());
		}
		return header;
		
	}
	
	/*
	 * 在FP的第二步当中，需要把header表当中的顺序，拿过来，根据第一频繁项集，重新排序并过滤
	 */
	private static String[] getOrderLine(String[] line, Map<String, Integer>frequentMap){
		
	
		return line;
	}
	
	
	
	
	private static ArrayList<String> getOrderLine2(String[] line, Map<String,FPNode>header){
		
		//这边所有的header按照倒叙排列而这个line 不一定都有,并且需要看是否在频繁项之内，header应该就是频繁的一项集了
		ArrayList<String> orderline=new ArrayList<String>();//形成数组，但不一定知道有多大，去掉频繁项以后多大
				//效率不一定高
		for(Entry<String,FPNode> entry: header.entrySet()){
			for(String idName:line){
				if (idName==entry.getKey())
					orderline.add(idName);
			}
		}		
		return orderline;
	}
	
	private static FPNode getFPTree(List<String[]>Matrix, Map<String, FPNode>header, 
			Map<String,Integer>frequentMap){
		FPNode root=new FPNode();
		
		for(String[] line: Matrix){
			//过滤完的每一条item
			ArrayList<String> orderline=getOrderLine2(line,header);
			FPNode parent=root;
			for(String idName:orderline){
				//search the root from beginning for every time
				if(parent.hasChild(idName)==-1){
					parent=parent.getChild(parent.hasChild(idName));
					parent.addCount();
				}else{
					FPNode node=new FPNode(idName);
					parent.addChildren(node);
					node.setParent(parent);
					FPNode nextnode=header.get(idName); //需要把这个和header的这个表格相互连接起来
					if(nextnode==null){
						header.put(idName, nextnode);
					}else{
						//循环找并且连接
						while(nextnode.next!=null){
							nextnode=nextnode.next;
						}
						nextnode.next=node;
					}
					parent=node;
				}
				
			}	
		}	
		return root;
		
	}
	
	/**
	 * 判断一颗fptree是否为单一路径
	 * 
	 * @param header
	 * @param tableLink
	 * @return
	 */
	private static boolean isSinglePath(Map<String, FPNode> header,
			String tableLink) {
		if (header.get(tableLink).next == null) //probem?
			return true;
		return false;
	}
	
	/**
	 * 求单一路径上的所有组合加上idName构成的频繁项
	 * 
	 * @param paths
	 * @param idName
	 * @return
	 */
	private static Map<Set<FPNode>, Long> getCombinationPattern(
			List<FPNode> paths) {
		Map<Set<FPNode>, Long> conditionFres = new HashMap<Set<FPNode>, Long>();
		int size = paths.size();
		for (int mask = 1; mask < (1 << size); mask++) {// 求所有组合，从1开始表示忽略空集
			Set<FPNode> set = new HashSet<FPNode>();
			// 找出每次可能的选择
			for (int i = 0; i < paths.size(); i++) {
				if ((mask & (1 << i)) > 0) {
					set.add(paths.get(i));
				}
			}
			long minValue = Long.MAX_VALUE;
			for (FPNode node : set) {
				if (node.count < minValue)
					minValue = node.count;
			}
			conditionFres.put(set, minValue);
		}
		return conditionFres;
	}
	
	/**
	 * 将叶子结点添加到频繁集中
	 * 
	 * @param leaf
	 * @param conditionFres
	 */
	
	private static Map<Set<FPNode>, Long> addLeafToFrequent(FPNode leaf,
			Map<Set<FPNode>, Long> conditionFres) {
		if (conditionFres.size() == 0) {
			Set<FPNode> set = new HashSet<FPNode>();
			set.add(leaf);
			conditionFres.put(set, leaf.count);
		} else {
			Set<Set<FPNode>> keys = new HashSet<Set<FPNode>>(
					conditionFres.keySet());
			for (Set<FPNode> set : keys) {
				Long count = conditionFres.get(set);
				conditionFres.remove(set);
				set.add(leaf);
				conditionFres.put(set, count);
			}
		}
		return conditionFres;
	}
	
	private static Holder getConditionFpTree(Map<List<String>, Long> paths) {
		List<String[]> matrix = new ArrayList<String[]>();
		for (Map.Entry<List<String>, Long> entry : paths.entrySet()) {
			for (long i = 0; i < entry.getValue(); i++) {
				matrix.add(entry.getKey().toArray(new String[0]));
			}
		}
		Map<String, Integer> frequentMap = new LinkedHashMap<String, Integer>();// 一级频繁项
		Map<String, FPNode> cHeader = getHeader(matrix, frequentMap);
		FPNode cRoot = getFPTree(matrix, cHeader, frequentMap);
		return new Holder(cRoot, cHeader);
	}


	private static Map<Set<FPNode>, Long> fpGrowth(FPNode root,
			Map<String, FPNode> header, String idName) {
		Map<Set<FPNode>, Long> conditionFres = new HashMap<Set<FPNode>, Long>();
		Set<String> keys = header.keySet();
		String[] keysArray = keys.toArray(new String[0]);
		String firstIdName = keysArray[keysArray.length - 1];
		if (isSinglePath(header, firstIdName)) {// 只有一条路径时，求路径上的所有组合即可得到调节频繁集
			if (idName == null)
				return conditionFres;
			FPNode leaf = header.get(firstIdName);
			List<FPNode> paths = new ArrayList<FPNode>();// 自顶向上保存路径结点
			paths.add(leaf);
			FPNode node = leaf;
			while (node.parent.idName != null) {
				paths.add(node.parent);
				node = node.parent;
			}
			conditionFres = getCombinationPattern(paths);
			FPNode tempNode = new FPNode(idName, -1L);
			conditionFres = addLeafToFrequent(tempNode, conditionFres);

		} else {
			for (int i = keysArray.length - 1; i >= 0; i--) {// 递归求条件树的频繁集
				String key = keysArray[i];
				List<FPNode> leafs = new ArrayList<FPNode>();
				FPNode link = header.get(key);
				while (link != null) {
					leafs.add(link);
					link = link.next;
				}
				Map<List<String>, Long> paths = new HashMap<List<String>, Long>();
				Long leafCount = 0L;
				FPNode noParentNode = null;
				for (FPNode leaf : leafs) {
					List<String> path = new ArrayList<String>();
					FPNode node = leaf;
					while (node.parent.idName != null) {
						path.add(node.parent.idName);
						node = node.parent;
					}
					leafCount += leaf.count;
					if (path.size() > 0)
						paths.put(path, leaf.count);
					else {// 没有父结点
						noParentNode = leaf;
					}
				}
				if (noParentNode != null) {
					Set<FPNode> oneItem = new HashSet<FPNode>();
					oneItem.add(noParentNode);
					if (idName != null)
						oneItem.add(new FPNode(idName, -2));
					conditionFres.put(oneItem, leafCount);
				}
				Holder holder = getConditionFpTree(paths);
				if (holder.header.size() != 0) {
					// if (idName != null)
					// key = idName + " " + key;
					Map<Set<FPNode>, Long> preFres = fpGrowth(holder.root,
							holder.header, key);
					if (idName != null) {
						FPNode tempNode = new FPNode(idName, leafCount);
						preFres = addLeafToFrequent(tempNode, preFres);
					}
					conditionFres.putAll(preFres);
				}
			}
		}
		return conditionFres;

	}

}

class Holder {
	public final FPNode root;
	public final Map<String, FPNode> header;

	public Holder(FPNode root, Map<String, FPNode> header) {
		this.root = root;
		this.header = header;
	}
}

